{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a31d4b3-ff93-4905-865c-5ca72e160b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "from datetime import datetime \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc1a4f4-40fe-434f-a09e-53999f19f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = 10\n",
    "news_list = []\n",
    "target_url = 'https://www.fxstreet.com/news?q=&hPP=17&idx=FxsIndexPro&p='\n",
    "output_csv = 'fxstreet.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf52d2ac-6464-44d1-865d-5c8fc7632aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page_no in range(0, pages) :\n",
    "    url = target_url + str(page_no) \n",
    "    \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    div = soup.find('div', class_= \"ais-hits\")\n",
    "    \n",
    "    for news_div in soup.find_all('div', class_= 'ais-hits--item'):\n",
    "        h4 = news_div.find('h4')\n",
    "        news_url = h4.a.get('href')\n",
    "        req = Request(news_url , headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        article_page = urlopen(req).read()\n",
    "        article_soup = BeautifulSoup(article_page, \"html.parser\")\n",
    "\n",
    "        news_title_a = article_soup.find(\"h1\", class_ = \"fxs_headline_large\").text\n",
    "        news_body = \"\"\n",
    "        for p in article_soup.find(\"div\", id = \"fxs_article_content\").find_all(\"p\"):\n",
    "            news_body += p.text\n",
    "        \n",
    "        news_date = article_soup.find('time').text\n",
    "        news_date = news_date.split(\" \")[0]\n",
    "        news_date = datetime.strptime(news_date, \"%m/%d/%Y\").date()\n",
    "        news_href = h4.a.get('href')\n",
    "        news_list.append([page_no, news_date, news_title_a, news_body ])\n",
    "\n",
    "    news_dataset = pd.DataFrame(news_list, columns = ['page', 'date','title','body'] )\n",
    "    news_dataset[\"source\"] = \"fxstreet\"\n",
    "\n",
    "news_dataset.to_csv(output_csv, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb86203-161a-4d00-8c43-ec1e47e3ddef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
